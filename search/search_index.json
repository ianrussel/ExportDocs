{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Development","text":""},{"location":"#whats-the-goal","title":"Whats the goal,","text":"<ol> <li>To update BI_Table hosted in mssql server latest version (&gt;= 2022 )</li> <li>The rows comes from B&amp;F Papers$Shipment LInes Tables hosted in mssql older version (2014) which hosted in hybrid connection</li> </ol>"},{"location":"#requirementsubuntu","title":"REQUIREMENTS(Ubuntu)","text":"<ol> <li>MSSQL VERSION 2014 &lt;= 2017</li> <li>MSSQL VERSION &gt;= 2022</li> </ol>"},{"location":"#steps","title":"steps","text":"<ol> <li>Create a view table vv_BiTable</li> <li> <p>Populate it with initial data from joined tables</p> <ul> <li>B&amp;F Papers$Sales Shipment Line</li> <li>B&amp;F Papers$Customer</li> <li>B&amp;F Papers$Item</li> <li>B&amp;F Papers$ Shipment Headers</li> </ul> <p>Note: This is a one time job only. This tables come from NavDatabase(MSSQL 2014 VERSION)</p> </li> <li> <p>If not exists, Create table BI_table in database with MSSQL 2022 </p> </li> <li>Run the scheduled job(aka cron job). See illustration</li> </ol>"},{"location":"diagram/","title":"Diagram","text":""},{"location":"diagram/#options","title":"options","text":"<ol> <li>SQL Server AGENT </li> <li>Azure functions</li> </ol> <pre><code>\ngraph TD;\n    TimerTrigger[Timer Triggered]\n    TimerTrigger --&gt; Init[Load config.json]\n    Init --&gt;|MSSQL SERVER VERSION 2022 | sql-server[Connect to SQL-SERVER-STAGING]\n    Init --&gt;|MSSQL SERVER VERSION 2014 | nav-server[Connect to NAV DB VIA Hybrid Connection]\n\n    sql-server --&gt; GetLatest[Query: Get latest line_no per document from B&amp;F Papers$ BITable]\n    nav-server --&gt; GetShipments[\"Query: Get shipment lines with joins (Shipment Lines, Customer, Shipment Headers and Items tables)\"]\n\n\n    GetLatest --&gt; Filter[Build lookup: documentNo \u2192 line_no]\n    GetShipments --&gt; Filter\n    Filter --&gt;|Filter newer lines| FilteredData[Filtered Shipment Rows]\n\n    FilteredData --&gt; Decision{Export format?}\n    Decision -- CSV --&gt; ExportCSV[Export to CSV]\n    Decision -- JSON --&gt; ExportJSON[Export to JSON]\n\n    ExportCSV --&gt; Transformer[Run Transformer Function]\n    ExportJSON --&gt; Transformer\n    Transformer --&gt; InsertNewRows[\"Insert new rows into SQL Server: B&amp;F Papers\\$BITable\"]\n    InsertNewRows --&gt; LoopBack[\"\ud83d\udd01 This process repeats every X minutes based on the scheduled Timer\"]\n\n</code></pre>"},{"location":"transformer/","title":"Transformer Function","text":"<p>The Transformer Function is responsible for mapping and transforming data between two schemas.</p> <p>It takes two parameters:</p> <ul> <li><code>source_schema</code>: a list of dictionaries that define the source column names and types.</li> <li><code>target_schema</code>: a list of dictionaries that define the target column names and types.</li> </ul> <p>The function: - Maps matching columns from <code>source_schema</code> to <code>target_schema</code> based on column name. - Casts each value to the data type defined in the <code>target_schema</code>. - Skips columns not present in <code>target_schema</code>.</p>"},{"location":"transformer/#example-transformer-logic","title":"Example Transformer Logic","text":"<p>```python from typing import List, Dict, Any</p> <p>def transform_data(rows: List[Dict[str, Any]], source_schema: List[Dict[str, str]], target_schema: List[Dict[str, str]]) -&gt; List[Dict[str, Any]]:     \"\"\"     Transforms a list of rows from source schema to target schema, casting values to the target type.</p> <pre><code>Parameters:\n    rows: List of data rows (dictionaries).\n    source_schema: List of source column definitions (e.g., [{'name': 'Quantity', 'type': 'str'}]).\n    target_schema: List of target column definitions (e.g., [{'name': 'Quantity', 'type': 'int'}]).\n\nReturns:\n    List of transformed rows.\n\"\"\"\ntype_casts = {\n    'int': int,\n    'float': float,\n    'str': str,\n    'bool': lambda x: str(x).lower() in ('true', '1', 'yes'),\n}\n\n# Build a lookup from target column name to type\ntarget_map = {col['name']: col['type'] for col in target_schema}\n\ntransformed_rows = []\n\nfor row in rows:\n    new_row = {}\n    for col_name, col_type in target_map.items():\n        if col_name in row:\n            try:\n                new_row[col_name] = type_casts[col_type](row[col_name])\n            except Exception:\n                new_row[col_name] = None  # or handle default/fallback\n        else:\n            new_row[col_name] = None  # column not found in input row\n    transformed_rows.append(new_row)\n\nreturn transformed_rows\n</code></pre>"}]}